{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8668a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4814 - accuracy: 0.8239\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3544 - accuracy: 0.8697\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3175 - accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7c4d40c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist #28*28 images of hand-written digits 0-9\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
    "\n",
    "#We normalize because apparently it has huge effects on the model\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "#We flatten the data to \n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#relu = rectified linear // apparently go to activation function, tweak this to have different outcome\n",
    "model.add(tf.keras.layers.Dense(136, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(136, activation=tf.nn.relu))\n",
    "\n",
    "#Output layer, still a dense layer but it need as many units in the layer as categories we are treating. for us it's 10 categories\n",
    "#also we use softmax for the activation function because it's used when dealing with probably distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "#adam optimizer is the default go to apparently\n",
    "#loss is degree of error, we have to minimise loss. loss is an important metric when optimising the model\n",
    "#many ways of calculating loss, categorical crossentropy seems to be used a lot. we use sparse here because it saves time in memory and computation compared to the classic one. when dealing with binary problems like telling cats and dogs appart we would have used binary_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "#1 epochs = training the neural network with all the data for one cycle\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b361b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8668\n",
      "0.3663046956062317 0.8668000102043152\n"
     ]
    }
   ],
   "source": [
    "#watch out for overfit, we have to check the validation loss and validation accuracy\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4febbbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00135942 0.         0.         0.0135775  0.07675477 0.\n",
      "  0.         0.00108359 0.00452712 0.         0.         0.\n",
      "  0.         0.00112628 0.00124281 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00407827 0.         0.0393841  0.14204153 0.13353227 0.06706289\n",
      "  0.05944322 0.         0.         0.         0.00114334 0.00349231\n",
      "  0.00461146 0.         0.         0.01550248]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00815655 0.         0.11158829 0.2130623  0.18505259 0.14494239\n",
      "  0.15851525 0.13328144 0.02603093 0.         0.         0.\n",
      "  0.         0.01351531 0.01242807 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16957044 0.24648383 0.21764709 0.19253541\n",
      "  0.11778563 0.16903988 0.18221649 0.12429049 0.07317407 0.02677434\n",
      "  0.08877055 0.14641589 0.08948208 0.07751239]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00148028\n",
      "  0.         0.08043127 0.22645859 0.23290633 0.22921287 0.23363847\n",
      "  0.23777287 0.176625   0.14373599 0.13797385 0.13948807 0.16995886\n",
      "  0.16255387 0.0991123  0.21376275 0.34105453]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00158012 0.00154801 0.00148028\n",
      "  0.         0.23313412 0.25380866 0.24230614 0.2449844  0.24770005\n",
      "  0.24547847 0.24164034 0.24333258 0.24287959 0.18750855 0.14784092\n",
      "  0.14180231 0.22075012 0.28460274 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21331772 0.24615064 0.22559537 0.23447005 0.24661839\n",
      "  0.25868808 0.2459747  0.2535186  0.25314211 0.25610924 0.25726649\n",
      "  0.25708875 0.27593765 0.21500556 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22497443 0.24943265 0.22768422 0.2239557  0.2141686\n",
      "  0.19814406 0.22972086 0.23767368 0.24059903 0.24353245 0.25959469\n",
      "  0.25363015 0.27368509 0.25104696 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00158012 0.00464404 0.\n",
      "  0.0163131  0.25528186 0.24068063 0.22141768 0.22921287 0.20767864\n",
      "  0.18603525 0.2459747  0.23541013 0.24858099 0.25610924 0.24678957\n",
      "  0.26054734 0.22187639 0.2597466  0.26870963]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00928807 0.\n",
      "  0.13458306 0.28442363 0.24286863 0.22977306 0.22921287 0.2195769\n",
      "  0.21795846 0.23947316 0.24333258 0.24287959 0.25382255 0.25610239\n",
      "  0.28245176 0.13402686 0.20754872 0.2893796 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00632047 0.         0.\n",
      "  0.07476837 0.27509826 0.24943265 0.24021729 0.23972722 0.2595983\n",
      "  0.25538568 0.23080445 0.24672792 0.25428239 0.26754269 0.25261008\n",
      "  0.25017156 0.23539171 0.11433822 0.        ]\n",
      " [0.         0.         0.00196864 0.00743066 0.01073107 0.01210602\n",
      "  0.00340005 0.         0.         0.         0.         0.\n",
      "  0.3221837  0.26344156 0.23739862 0.23290633 0.23341861 0.23688345\n",
      "  0.24437767 0.23947316 0.24446436 0.25428239 0.26182596 0.25028188\n",
      "  0.25132443 0.28720041 0.09569612 0.        ]\n",
      " [0.         0.00677527 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.09796732 0.2244617  0.30197776\n",
      "  0.30994887 0.24129382 0.23302261 0.23081749 0.22921287 0.2249852\n",
      "  0.23226887 0.2362224  0.2535186  0.25428239 0.25039252 0.25028188\n",
      "  0.25824161 0.27481137 0.19760627 0.        ]\n",
      " [0.         0.         0.         0.         0.0321932  0.07609496\n",
      "  0.13940217 0.17644206 0.29930777 0.36026691 0.34056258 0.32862285\n",
      "  0.2949952  0.26344156 0.21880057 0.21410672 0.22185283 0.24878171\n",
      "  0.24657927 0.25355982 0.19919318 0.2143726  0.28583621 0.28869724\n",
      "  0.26861739 0.26805371 0.26720344 0.        ]\n",
      " [0.         0.12873017 0.36813591 0.38639423 0.40062647 0.38220425\n",
      "  0.38080592 0.34299018 0.32306235 0.33814525 0.32198644 0.30937917\n",
      "  0.27188498 0.18534163 0.2680307  0.20157364 0.21659565 0.24121009\n",
      "  0.28070408 0.27631519 0.25012326 0.26682547 0.25267921 0.24562547\n",
      "  0.25363015 0.26129606 0.30573045 0.        ]\n",
      " [0.02264812 0.45620167 0.44885021 0.41611686 0.39526094 0.36490994\n",
      "  0.35870558 0.35288412 0.32464599 0.32392419 0.3173424  0.32566229\n",
      "  0.32626197 0.09325365 0.16410043 0.26632787 0.24077866 0.23904677\n",
      "  0.20695046 0.1668727  0.21616988 0.23945875 0.23324234 0.24329727\n",
      "  0.25593588 0.25679095 0.27963151 0.        ]\n",
      " [0.73983865 0.52621282 0.38979097 0.39010956 0.39704945 0.39603969\n",
      "  0.38930605 0.38586395 0.39432611 0.34762596 0.30031428 0.31826087\n",
      "  0.2949952  0.28092662 0.07111019 0.07624288 0.11145213 0.12655417\n",
      "  0.18493445 0.23730599 0.25012326 0.24516015 0.24810583 0.25959469\n",
      "  0.25708875 0.25228585 0.28460274 0.14985729]\n",
      " [0.56620305 0.46071852 0.41735195 0.37896357 0.34518263 0.35453335\n",
      "  0.35870558 0.37102303 0.34206602 0.29232183 0.30495831 0.30493832\n",
      "  0.26916613 0.24828784 0.26256069 0.20366249 0.23867579 0.2650066\n",
      "  0.26309128 0.24164034 0.24672792 0.24173931 0.23895907 0.25843059\n",
      "  0.25363015 0.24890702 0.28584554 0.34622202]\n",
      " [0.36236995 0.45846009 0.36026135 0.36038692 0.38095285 0.3406979\n",
      "  0.31450489 0.31330833 0.30722596 0.30338266 0.31269837 0.31678059\n",
      "  0.29771405 0.2576132  0.24068063 0.24648383 0.23657292 0.23363847\n",
      "  0.21905926 0.22321933 0.21051098 0.20639064 0.20237203 0.2002255\n",
      "  0.20866844 0.2308866  0.25601818 0.59426168]\n",
      " [0.         0.27552774 0.43113243 0.35852926 0.32014347 0.2957327\n",
      "  0.31110484 0.32320228 0.32306235 0.33182478 0.3297265  0.30641861\n",
      "  0.28683865 0.24479083 0.21880057 0.20470691 0.20397843 0.20659698\n",
      "  0.21465606 0.2069655  0.22409233 0.21893371 0.20122869 0.18159987\n",
      "  0.19252834 0.19935087 0.26098941 0.47540935]\n",
      " [0.         0.         0.14567945 0.3510986  0.37916434 0.33032132\n",
      "  0.29750463 0.28362649 0.27713682 0.28600136 0.28638217 0.27829323\n",
      "  0.2569313  0.21914607 0.21114255 0.20679576 0.21449278 0.22606686\n",
      "  0.23116807 0.22755369 0.23880546 0.2143726  0.21494883 0.22583574\n",
      "  0.22134995 0.24327564 0.21127714 0.        ]\n",
      " [0.01509875 0.         0.         0.         0.11804173 0.34588619\n",
      "  0.37740587 0.39081092 0.37848972 0.38238856 0.38081089 0.3597088\n",
      "  0.33169967 0.2576132  0.24068063 0.20157364 0.20082412 0.19361707\n",
      "  0.20034566 0.19721319 0.20485208 0.20068924 0.18979524 0.1955691\n",
      "  0.11413357 0.06532401 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06595965 0.09660198 0.06952519 0.11145684 0.06069161\n",
      "  0.04757987 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd0d73b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FashionGuess.model\\assets\n",
      "[[1.31885417e-05 4.66706283e-08 7.09569076e-06 ... 1.37714241e-02\n",
      "  4.74771441e-05 9.83453870e-01]\n",
      " [4.35023307e-04 1.04239632e-07 9.69959021e-01 ... 9.48623491e-09\n",
      "  9.60695343e-06 1.58267432e-09]\n",
      " [1.18624754e-04 9.99490499e-01 3.75545756e-06 ... 1.91040161e-08\n",
      "  6.06488129e-07 4.50849598e-08]\n",
      " ...\n",
      " [2.37056942e-04 1.48018501e-07 2.47120654e-04 ... 2.36161554e-06\n",
      "  9.97963786e-01 9.19300973e-08]\n",
      " [1.34626216e-05 9.99225736e-01 3.87619593e-06 ... 5.08877207e-08\n",
      "  7.53927054e-07 1.60421948e-07]\n",
      " [4.88131218e-06 4.31739323e-07 2.12262239e-06 ... 4.48326953e-03\n",
      "  5.92491007e-04 5.86195574e-06]]\n"
     ]
    }
   ],
   "source": [
    "#Saving the model\n",
    "model.save('FashionGuess.model')\n",
    "\n",
    "#Reload model\n",
    "tmpModel = tf.keras.models.load_model('FashionGuess.model')\n",
    "\n",
    "#predictions\n",
    "predictions = tmpModel.predict([x_test])\n",
    "\n",
    "#output probabilty distribution\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4c7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Label Description\n",
    "#0 T-shirt/top\n",
    "#1 Trouser\n",
    "#2 Pullover\n",
    "#3Dress\n",
    "#4 Coat\n",
    "#5 Sandal\n",
    "#6 Shirt\n",
    "#7 Sneaker\n",
    "#8 Bag\n",
    "#9 Ankle boot\n",
    "import numpy as np\n",
    "\n",
    "#Checking output\n",
    "print(np.argmax(predictions[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7433ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQFklEQVR4nO3de4wd5XnH8d+z612vvbaxFxvbtS2HIDvUpMVOF5IGiohIIiBCkD+KQtuUqkgmUmiDFKlB9I/wJ0qb0kqtojrFwqkSokgEhUg0XNxUBCmlLOAa29zBgB3fXez1bb2Xp3/sEC2w88xy7snz/UirPTvPmZnXs+fnOXveeec1dxeA335d7W4AgNYg7EAShB1IgrADSRB2IIlZrdxZr832PvW3cpdAKmd0Umd9xKar1RV2M7ta0j9J6pb0b+5+d/T8PvXrk3ZVPbsEEHjKt5bWan4bb2bdkv5F0jWS1km6yczW1bo9AM1Vz9/sl0p61d1fd/ezkn4o6frGNAtAo9UT9hWS3p7y855i2XuY2UYzGzKzoVGN1LE7APVo+qfx7r7J3QfdfbBHs5u9OwAl6gn7Xkmrpvy8slgGoAPVE/anJa0xs/PNrFfSlyQ91JhmAWi0mrve3H3MzG6T9Igmu942u/vOhrUMQEPV1c/u7g9LerhBbQHQRFwuCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiirimbzWy3pGFJ45LG3H2wEY0C0Hh1hb3wGXc/3IDtAGgi3sYDSdQbdpf0qJk9Y2Ybp3uCmW00syEzGxrVSJ27A1Cret/GX+7ue83sPEmPmdmL7v7E1Ce4+yZJmyRpgQ14nfsDUKO6zuzuvrf4flDSg5IubUSjADRezWE3s34zm//uY0mfl7SjUQ0D0Fj1vI1fKulBM3t3Oz9w9581pFUAGq7msLv765IubmBbADQRXW9AEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTRiBtOAqW6zx0orY0fORqu29XXF9aP3bA+rJ/z0+dLaxOnz4TramI8rleZHPpdzlt/0ybO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBP3sCM1a8Tthff8XVof1Jc8Ol9ZG/+Cj4bq7r+sO6xf+czyf6Ogn1pbW3lkT9+Gf80Y8VdnpxT1h3bvifvaF//V6aW38wMFw3bAPP+i+58wOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nQz47Q2N5fhfXFm+J6NGp74tpLwnXPeSnuZz+zemFY10T53nuHJ8JVj6+eHW867mbX2JyKfvaxsXgDTVB5ZjezzWZ20Mx2TFk2YGaPmdkrxfdFzW0mgHrN5G38fZKuft+yOyRtdfc1krYWPwPoYJVhd/cnJL3//kHXS9pSPN4i6YbGNgtAo9X6N/tSd99XPN4vaWnZE81so6SNktSnuTXuDkC96v403t1dwecw7r7J3QfdfbBH8YceAJqn1rAfMLPlklR8rximA6Ddag37Q5JuLh7fLOknjWkOgGap/JvdzO6XdKWkxWa2R9I3Jd0t6UdmdoukNyXd2MxGon1sw0VhfXxBb1jvPn62tPb2Z+N+9EU743urH7o43nfvsaCf/US87dF5cT/5nENxP/3ZBfH6h6/7WGlt0X2/DNftmjOntGany8/flWF395tKSldVrQugc3C5LJAEYQeSIOxAEoQdSIKwA0m0doirmaynvLvEx0bj9aNpbiumyLXuuJvHmznksCved1dffGWhj1dMHxwM5fTR8q4vSXrrrk+H9TkH4i6qvqNxfcGp8uN64bfeCNfddVd8m+ruE/G5as6h8tfE7GPxMT2+Ot72rFPx623u/rhr7sgXyqeMXnRfuKomTp0qrbmX75czO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dp+dvfKft96tl2Xin76urY/EffpRv2m9Tr0lT8M62dWxr+PJc/F54Ous/Fx6TpR3p88tv9AuO7ar8T1w7fG/7bRueW/01mn4t/JgjfjayOqDPxnfA3Bgt3LS2vv/Hn871r4vXgIbBnO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxG/WePY6NHW8epWK8exHbrk0rB/7zOmw3rujfFqtVf9xLFx32dZ428fWLwnrZxbG/7axuQOltf4XwlUrLf7XuL/52J99qrR2cll8G+quipdL/9vxcau6hsCC+ujvx/3steLMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/PaMZ69gs+J/alU//NmrLymtnVwWb/vs/His/PGPxWOrl/60L17//PKaP7czXFfr1obl0f74fOAVp4ueExX3vG+i0f7y495zMh6Hf7Yv/p2dvKQ/rC9/Lv6dTZwpH+c/b198zEauKX8t+pPl1x5UntnNbLOZHTSzHVOW3WVme81sW/F1bdV2ALTXTN7G3yfp6mmW3+Pu64uvhxvbLACNVhl2d39C0tEWtAVAE9XzAd1tZra9eJu/qOxJZrbRzIbMbGhUI3XsDkA9ag37dyRdIGm9pH2Svl32RHff5O6D7j7Yo3gCQwDNU1PY3f2Au4/75JSR35UUD9sC0HY1hd3Mpt4H94uSdpQ9F0BnqOxnN7P7JV0pabGZ7ZH0TUlXmtl6SS5pt6RbG9Kaqnu3R6s2ef71dy7oKa2NlQ8nlyTNqrgt/JrvVTxhaFdY7r/i4tKabbgoXNf2HwnrJ1YuDuuz3wnLOrShfNz4ikfides10V3+eho5J36t9Q7H/fDz91T0hV/x8bDe8+hQ+baf2xeuu+uO8nvOnw1Ou5Vhd/ebpll8b9V6ADoLl8sCSRB2IAnCDiRB2IEkCDuQREfdStq6K4ZTBtMm+0h8Ke6s5cvC+pl1K+J6cEfl/r1xN83pJXE3zyu3lXfrSdLvfqPids7zyn+NvQdPhOuO7dsf1k9fEB+Xnu3xVZFnF5Qfm4k/2hCu2/WL58J6lWio6Knz4tfawPb4FtwT2+Lu0D13fjqsr3y8vKt4Yn48fLZ7QXDL9e7y482ZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS6KhbSXvzZmyWuuL/117/43iIrFQ+RHZsbrzueH88HPLCv34trPuKimsEFpXv/8h18RDVFbteDusX/mM8/Hb/5RV3HwouMXj1T+PrC9b+It50V3/cH90zHAxrPi+esnlsfvzvqjpLrnx8uOIZ5f5v/cKwvujx8oN64Hh5yzizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASFo0Rb7TBi/v8fx5ZVVp/aywee31ovLxvdO/YwnDdo+PzwvrmNy8L63teXFpa8764H717OO6HX3tvfDvnX30uHs9+fG35/uetPB6uO/HfpTN3SZKWPVU+tbAkHdwQT018Zkn562t8Vbztrj3xtqtuPH7u9mDfvfHaY3PibR9bG+ema6Ri+4vKrwGYd97JcN3en51TWnvpgXt06uDb0+6cMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNHS8ewvv7FYn/2TvyytH/69uF915NygNhD3dfvsibBe1Re+8LXyftOxufG47L7DcZ/sC38V93UvWX0orHftKh+zPnwgvr6g66LTYf2dQ/HvZNkv4z7h7tPlNymw0YrfWU88F8Bb1ywM6yPl3dGac7ji9VDRT77wxbg+MSuuD/eUv95OnVoQrtvVV75tD3ZbeWY3s1Vm9nMz22VmO83sa8XyATN7zMxeKb7Hr1gAbTWTt/Fjkr7u7uskfUrSV81snaQ7JG119zWSthY/A+hQlWF3933u/mzxeFjSC5JWSLpe0pbiaVsk3dCkNgJogA/1N7uZfUTSBklPSVrq7vuK0n5J0148bmYbJW2UpNmzF9baTgB1mvGn8WY2T9IDkm539/eMrvDJ0TTTfgrl7pvcfdDdB3t74xsEAmieGYXdzHo0GfTvu/uPi8UHzGx5UV8u6WBzmgigESqHuJqZafJv8qPufvuU5X8n6Yi7321md0gacPe/iba1wAb8k3ZV/a0GMK2nfKuO+9FpO+Bm8jf7ZZK+LOl5M9tWLLtT0t2SfmRmt0h6U9KNDWgrgCapDLu7P6ny+wRwmgZ+Q3C5LJAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lUht3MVpnZz81sl5ntNLOvFcvvMrO9Zrat+Lq2+c0FUKuZzM8+Junr7v6smc2X9IyZPVbU7nH3v29e8wA0ykzmZ98naV/xeNjMXpC0otkNA9BYH+pvdjP7iKQNkp4qFt1mZtvNbLOZLSpZZ6OZDZnZ0KhG6mstgJrNOOxmNk/SA5Jud/fjkr4j6QJJ6zV55v/2dOu5+yZ3H3T3wR7Nrr/FAGoyo7CbWY8mg/59d/+xJLn7AXcfd/cJSd+VdGnzmgmgXjP5NN4k3SvpBXf/hynLl0952hcl7Wh88wA0ykw+jb9M0pclPW9m24pld0q6yczWS3JJuyXd2oT2AWiQmXwa/6Qkm6b0cOObA6BZuIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhLl763ZmdkjSm1MWLZZ0uGUN+HA6tW2d2i6JttWqkW1b7e5Lpiu0NOwf2LnZkLsPtq0BgU5tW6e2S6JttWpV23gbDyRB2IEk2h32TW3ef6RT29ap7ZJoW61a0ra2/s0OoHXafWYH0CKEHUiiLWE3s6vN7CUze9XM7mhHG8qY2W4ze76YhnqozW3ZbGYHzWzHlGUDZvaYmb1SfJ92jr02ta0jpvEOphlv67Fr9/TnLf+b3cy6Jb0s6XOS9kh6WtJN7r6rpQ0pYWa7JQ26e9svwDCzKySdkPQ9d/94sexbko66+93Ff5SL3P0bHdK2uySdaPc03sVsRcunTjMu6QZJf6E2HrugXTeqBcetHWf2SyW96u6vu/tZST+UdH0b2tHx3P0JSUfft/h6SVuKx1s0+WJpuZK2dQR33+fuzxaPhyW9O814W49d0K6WaEfYV0h6e8rPe9RZ8727pEfN7Bkz29juxkxjqbvvKx7vl7S0nY2ZRuU03q30vmnGO+bY1TL9eb34gO6DLnf3T0i6RtJXi7erHckn/wbrpL7TGU3j3SrTTDP+a+08drVOf16vdoR9r6RVU35eWSzrCO6+t/h+UNKD6rypqA+8O4Nu8f1gm9vza500jfd004yrA45dO6c/b0fYn5a0xszON7NeSV+S9FAb2vEBZtZffHAiM+uX9Hl13lTUD0m6uXh8s6SftLEt79Ep03iXTTOuNh+7tk9/7u4t/5J0rSY/kX9N0t+2ow0l7fqopP8tvna2u22S7tfk27pRTX62cYukcyVtlfSKpMclDXRQ2/5d0vOStmsyWMvb1LbLNfkWfbukbcXXte0+dkG7WnLcuFwWSIIP6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8H6nns8E17X0MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cf388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
