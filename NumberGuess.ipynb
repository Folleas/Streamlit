{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f38c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2373 - accuracy: 0.9301\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0950 - accuracy: 0.9704\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0651 - accuracy: 0.9796: 0s - los\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2074bcfcc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist #28*28 images of hand-written digits 0-9\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#We normalize because apparently it has huge effects on the model\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "#We flatten the data to \n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#relu = rectified linear // apparently go to activation function, tweak this to have different outcome\n",
    "model.add(tf.keras.layers.Dense(192, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(192, activation=tf.nn.relu))\n",
    "\n",
    "#Output layer, still a dense layer but it need as many units in the layer as categories we are treating. for us it's 10 categories\n",
    "#also we use softmax for the activation function because it's used when dealing with probably distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "#adam optimizer is the default go to apparently\n",
    "#loss is degree of error, we have to minimise loss. loss is an important metric when optimising the model\n",
    "#many ways of calculating loss, categorical crossentropy seems to be used a lot. we use sparse here because it saves time in memory and computation compared to the classic one. when dealing with binary problems like telling cats and dogs appart we would have used binary_categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "#1 epochs = training the neural network with all the data for one cycle\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314cdc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0920 - accuracy: 0.9737\n",
      "0.09199883788824081 0.9736999869346619\n"
     ]
    }
   ],
   "source": [
    "#watch out for overfit, we have to check the validation loss and validation accuracy\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e579f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f431add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NumberGuess.model\\assets\n",
      "[[5.0459077e-09 4.0418321e-08 1.3309389e-05 ... 9.9894232e-01\n",
      "  2.8684237e-06 1.0556241e-05]\n",
      " [2.8546392e-09 2.5870628e-04 9.9973673e-01 ... 1.4022508e-09\n",
      "  1.6119289e-07 1.5800802e-11]\n",
      " [1.9068793e-07 9.9979788e-01 4.1201738e-06 ... 1.4346349e-04\n",
      "  2.0602933e-05 1.1179502e-06]\n",
      " ...\n",
      " [6.0518557e-10 4.9788781e-07 1.6997188e-08 ... 7.6739278e-05\n",
      "  5.5714418e-06 6.9749372e-06]\n",
      " [2.8571974e-09 4.2586514e-08 3.1020559e-09 ... 7.7901166e-07\n",
      "  6.8957532e-05 2.5985027e-09]\n",
      " [4.1571141e-08 1.0686956e-10 1.5442562e-09 ... 1.7944786e-11\n",
      "  3.2318797e-09 9.2801140e-12]]\n"
     ]
    }
   ],
   "source": [
    "#Saving the model\n",
    "model.save('NumberGuess.model')\n",
    "\n",
    "#Reload model\n",
    "tmpModel = tf.keras.models.load_model('NumberGuess.model')\n",
    "\n",
    "#predictions\n",
    "predictions = tmpModel.predict([x_test])\n",
    "\n",
    "#output probabilty distribution\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0cd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Checking output\n",
    "print(np.argmax(predictions[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d204efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d0570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
